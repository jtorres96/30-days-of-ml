{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0be0f0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.01155,
     "end_time": "2021-08-24T19:38:56.070070",
     "exception": false,
     "start_time": "2021-08-24T19:38:56.058520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Implementing k-folds into Pipeline for 30 Days of ML Challenge, by Juan Torres\n",
    "\n",
    "#### Based on Abhishek Thakur's tutorials and notebooks:\n",
    "\n",
    "https://www.youtube.com/watch?v=t5fhRP62YdE\n",
    "\n",
    "https://www.kaggle.com/abhishek/competition-part-1-baseline?scriptVersionId=72291885"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c443b",
   "metadata": {
    "papermill": {
     "duration": 0.009581,
     "end_time": "2021-08-24T19:38:56.089871",
     "exception": false,
     "start_time": "2021-08-24T19:38:56.080290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Having created a new .csv file in our previous notebook that took the training data and divided it into folds for cross validation, we will now implement said folds into our previously built pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8d43ed",
   "metadata": {
    "papermill": {
     "duration": 0.009501,
     "end_time": "2021-08-24T19:38:56.109449",
     "exception": false,
     "start_time": "2021-08-24T19:38:56.099948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c185e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T19:38:56.145457Z",
     "iopub.status.busy": "2021-08-24T19:38:56.144748Z",
     "iopub.status.idle": "2021-08-24T19:38:57.205072Z",
     "shell.execute_reply": "2021-08-24T19:38:57.205519Z",
     "shell.execute_reply.started": "2021-08-24T19:31:16.394879Z"
    },
    "papermill": {
     "duration": 1.086286,
     "end_time": "2021-08-24T19:38:57.205810",
     "exception": false,
     "start_time": "2021-08-24T19:38:56.119524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/train-folds-30-days-of-ml/train_folds.csv\n",
      "/kaggle/input/30-days-of-ml/sample_submission.csv\n",
      "/kaggle/input/30-days-of-ml/train.csv\n",
      "/kaggle/input/30-days-of-ml/test.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# For one-hot encoding categorical variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# from sklearn.model_selection import train_test_split We won't be needing this anymore!\n",
    "\n",
    "# For the construction of the pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# For training the XGBoost model\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da32d5",
   "metadata": {
    "papermill": {
     "duration": 0.009948,
     "end_time": "2021-08-24T19:38:57.226337",
     "exception": false,
     "start_time": "2021-08-24T19:38:57.216389",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We have to account for the fact that we are working with k-folds, so the data loading and processing and the pipeline construction will be intertwined:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe1c8bf",
   "metadata": {
    "papermill": {
     "duration": 0.009878,
     "end_time": "2021-08-24T19:38:57.246771",
     "exception": false,
     "start_time": "2021-08-24T19:38:57.236893",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Loading and preparing data and pipeline construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19bd9257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T19:38:57.272428Z",
     "iopub.status.busy": "2021-08-24T19:38:57.271639Z",
     "iopub.status.idle": "2021-08-24T19:39:01.104497Z",
     "shell.execute_reply": "2021-08-24T19:39:01.104012Z",
     "shell.execute_reply.started": "2021-08-24T19:31:17.380601Z"
    },
    "papermill": {
     "duration": 3.847501,
     "end_time": "2021-08-24T19:39:01.104637",
     "exception": false,
     "start_time": "2021-08-24T19:38:57.257136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the training and test data. \n",
    "X_full = pd.read_csv(\"../input/train-folds-30-days-of-ml/train_folds.csv\")\n",
    "X_test_full = pd.read_csv(\"../input/30-days-of-ml/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ab097d",
   "metadata": {
    "papermill": {
     "duration": 0.010117,
     "end_time": "2021-08-24T19:39:01.125026",
     "exception": false,
     "start_time": "2021-08-24T19:39:01.114909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We have our data loaded. Now, let's do some data preprocessing to correctly use the folds we set up previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e40184f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T19:39:01.182779Z",
     "iopub.status.busy": "2021-08-24T19:39:01.181714Z",
     "iopub.status.idle": "2021-08-24T19:39:01.184828Z",
     "shell.execute_reply": "2021-08-24T19:39:01.184333Z",
     "shell.execute_reply.started": "2021-08-24T19:31:19.045282Z"
    },
    "papermill": {
     "duration": 0.049681,
     "end_time": "2021-08-24T19:39:01.184952",
     "exception": false,
     "start_time": "2021-08-24T19:39:01.135271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We select all features except \"id\", \"target\" and \"kfold\", as these are not predictors of our target.\n",
    "useful_features = [c for c in X_full.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
    "\n",
    "# Select numerical columns\n",
    "num_cols = [col for col in useful_features if 'cont' in col]\n",
    "\n",
    "# We select categorical columns. Note that we dropped the cardinality check.\n",
    "object_cols = [col for col in useful_features if 'cat' in col]\n",
    "\n",
    "# We build X_test out of X_test_full, but only selecting the useful features.\n",
    "X_test = X_test_full[useful_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b34afd",
   "metadata": {
    "papermill": {
     "duration": 0.010006,
     "end_time": "2021-08-24T19:39:01.205173",
     "exception": false,
     "start_time": "2021-08-24T19:39:01.195167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we begin constructing the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d193e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T19:39:01.231802Z",
     "iopub.status.busy": "2021-08-24T19:39:01.231091Z",
     "iopub.status.idle": "2021-08-24T19:39:01.233933Z",
     "shell.execute_reply": "2021-08-24T19:39:01.234314Z",
     "shell.execute_reply.started": "2021-08-24T19:31:19.078449Z"
    },
    "papermill": {
     "duration": 0.01906,
     "end_time": "2021-08-24T19:39:01.234463",
     "exception": false,
     "start_time": "2021-08-24T19:39:01.215403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Preprocessing for categorical data and one-hot encoding\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, num_cols),('cat', categorical_transformer, object_cols)])\n",
    "\n",
    "# Define the model \n",
    "model = XGBRegressor(tree_method = 'gpu_hist') # In Abhishek's method random_state was altered with each fold (as random_state = fold), so we'll trade repeatability for some induced randomness.\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b534622d",
   "metadata": {
    "papermill": {
     "duration": 0.009894,
     "end_time": "2021-08-24T19:39:01.254744",
     "exception": false,
     "start_time": "2021-08-24T19:39:01.244850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, we set up the folds within a for loop that will loop across all of the k-folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b489ac67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T19:39:01.283019Z",
     "iopub.status.busy": "2021-08-24T19:39:01.282409Z",
     "iopub.status.idle": "2021-08-24T19:39:23.412121Z",
     "shell.execute_reply": "2021-08-24T19:39:23.412843Z",
     "shell.execute_reply.started": "2021-08-24T19:31:19.141550Z"
    },
    "papermill": {
     "duration": 22.14792,
     "end_time": "2021-08-24T19:39:23.413072",
     "exception": false,
     "start_time": "2021-08-24T19:39:01.265152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7233329089723132\n",
      "1 0.7303783741255304\n",
      "2 0.726387042692036\n",
      "3 0.7254889468557322\n",
      "4 0.7201351340010433\n"
     ]
    }
   ],
   "source": [
    "# We set up a list to store the final predictions.\n",
    "final_predictions = []\n",
    "# We set the loop to loop across all of the folds. Since we have 5 folds, the loop range will be range(5).\n",
    "for fold in range(5):\n",
    "    X_train = X_full[X_full.kfold != fold].reset_index(drop=True) # We set the training data to be all folds different from the current fold number in the loop. We also reset the indices.\n",
    "    X_valid = X_full[X_full.kfold == fold].reset_index(drop=True) # The validation data is the current fold number in the loop. We also reset the indices.\n",
    "    X_test_copy = X_test.copy() # We copy the original X_test to not alter or overwrite over it.\n",
    "    \n",
    "    y_train = X_train.target # We set the training target equal to the target in the training set. This has to be done every iteration (as the fold and the data changes).\n",
    "    y_valid = X_valid.target # We set the validation target equal to the target in the validation set. This has to be done every iteration (as the fold and the data changes).\n",
    "    \n",
    "    X_train = X_train[useful_features] # We set our training data to be the previously defined useful features of X_train.\n",
    "    X_valid = X_valid[useful_features] # We set our validation data to be the previously defined useful features of X_valid.\n",
    "    \n",
    "    # We activate the pipeline, which preprocesses the training data and fits the model (will take about 10 minutes to run)\n",
    "    my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    preds_valid = my_pipeline.predict(X_valid) # We instruct the pipeline to make predictions on X_valid.\n",
    "    preds_test = my_pipeline.predict(X_test) # We instruct the pipeline to make predictions on X_test.\n",
    "    final_predictions.append(preds_test) # We append each of the test predictions on to our final_predictions list.\n",
    "    print(fold, mean_squared_error(y_valid, preds_valid, squared=False)) # Print the fold number, and the mean squared error for each fold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff66fed",
   "metadata": {
    "papermill": {
     "duration": 0.011155,
     "end_time": "2021-08-24T19:39:23.438292",
     "exception": false,
     "start_time": "2021-08-24T19:39:23.427137",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "final_predictions is a list of lists with the predicted values for each fold, we'll take the average across folds and merge them into a single predictions variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5c4df08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T19:39:23.466816Z",
     "iopub.status.busy": "2021-08-24T19:39:23.466047Z",
     "iopub.status.idle": "2021-08-24T19:39:23.473988Z",
     "shell.execute_reply": "2021-08-24T19:39:23.473534Z",
     "shell.execute_reply.started": "2021-08-24T19:33:40.559913Z"
    },
    "papermill": {
     "duration": 0.024259,
     "end_time": "2021-08-24T19:39:23.474118",
     "exception": false,
     "start_time": "2021-08-24T19:39:23.449859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = np.mean(np.column_stack(final_predictions), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ebf745",
   "metadata": {
    "papermill": {
     "duration": 0.011268,
     "end_time": "2021-08-24T19:39:23.496831",
     "exception": false,
     "start_time": "2021-08-24T19:39:23.485563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, we create the submission file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac24e55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T19:39:23.536429Z",
     "iopub.status.busy": "2021-08-24T19:39:23.533698Z",
     "iopub.status.idle": "2021-08-24T19:39:25.301488Z",
     "shell.execute_reply": "2021-08-24T19:39:25.300925Z",
     "shell.execute_reply.started": "2021-08-24T19:33:41.163596Z"
    },
    "papermill": {
     "duration": 1.793029,
     "end_time": "2021-08-24T19:39:25.301628",
     "exception": false,
     "start_time": "2021-08-24T19:39:23.508599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the model to generate predictions\n",
    "predictions = my_pipeline.predict(X_test)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "output = pd.DataFrame({'Id': X_test_full.id,\n",
    "                       'target': predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37.678215,
   "end_time": "2021-08-24T19:39:26.837018",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-24T19:38:49.158803",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
